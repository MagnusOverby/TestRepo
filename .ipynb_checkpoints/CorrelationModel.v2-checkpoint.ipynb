{
 "metadata": {
  "name": "",
  "signature": "sha256:c8fc62dda987ae316797f280a46dc91b3b8cd20907c6c1d810148188be93e76e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "engine='python'\n",
      "import os\n",
      "import pytz\n",
      "from datetime import datetime\n",
      "import pandas as pd\n",
      "import pandas.io.data as web\n",
      "import numpy as np\n",
      "import subprocess\n",
      "import matplotlib.pyplot as plt\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Computation engine\n",
      "def ComputeCorrelation(InSeries,inCols,percentile,minCorr):\n",
      "    InSeries1= InSeries.resample('W',how='last')\n",
      "    inRets = InSeries1.pct_change()\n",
      "    #inRets = inRets.resample('W',how='mean').fillna(0)\n",
      "    iMax = len(inRets)\n",
      "    jMax = len(inRets.columns)\n",
      "    NrOfDs = 52 #years worth of data\n",
      "    Carrier = np.zeros([iMax-NrOfDs,jMax,jMax])\n",
      "    for i in xrange(0,iMax-NrOfDs):\n",
      "        Carrier[i,:,:]=inRets[i:i+NrOfDs].corr().as_matrix()\n",
      "    #Build a new Correlation matrix with the Prenentile (variable) Quantile of all our Correlations\n",
      "    #Percentile is our input parameter which we fudge different \n",
      "    adjCorrelation = np.zeros([jMax,jMax])\n",
      "    for i in range(0,jMax):\n",
      "        for j in range(0,jMax):\n",
      "            tmp = np.max([np.percentile(Carrier[:,i,j],percentile)*100,minCorr])\n",
      "            adjCorrelation[i,j] = tmp\n",
      "    #Now build a datagrid with these\n",
      "    Corrs = pd.DataFrame(adjCorrelation,columns=inCols,index=inCols).fillna(minCorr)\n",
      "    return Corrs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Print to a Csv file that resembles simple_input....\n",
      "#1 start by enumerating all the instruments Sophies Ref and instrument type need [number,ref,type,value]\n",
      "def WriteToCsv(Corrs,path,nrInput,rets):\n",
      "    nrInput = len(Corrs)\n",
      "    Cols = []\n",
      "    cols = Corrs.columns\n",
      "    iMax = len(rets)\n",
      "    dvol =  rets[iMax-52:iMax].std()\n",
      "    yvol = dvol*np.sqrt(52)*100\n",
      "    Cols.append(['col','ref type','ref','type','vol'])\n",
      "    for i in range(0,nrInput):\n",
      "        tmpRow = [i+1,'SOPHISREF',cols[i],'S',np.round(yvol.ix[i],8)]\n",
      "        Cols.append(tmpRow)\n",
      "    #add empty row\n",
      "    Cols.append([])\n",
      "    #now index and add the correlation matrix with headers 1 to i and indexing 1 to i\n",
      "    #header\n",
      "    tmpRow = ['correlation']\n",
      "    for i in range(0,nrInput):\n",
      "        tmpRow.append(i+1)\n",
      "    Cols.append(tmpRow)\n",
      "\n",
      "    for i in range(0,nrInput):\n",
      "        tmpRow = [i+1]\n",
      "        for j in range(0,nrInput):\n",
      "            tmpRow.append(np.round(Corrs.ix[i,j]/100,8))\n",
      "        Cols.append(tmpRow)\n",
      "    Cols.append(['Sophis'])\n",
      "    df = pd.DataFrame(Cols)\n",
      "    df.to_csv(path,index=False,header=False,sep=';',line_terminator=',')\n",
      "    print \"written to file: \"+path+ \" at : \" + str(datetime.now())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def MakeNwriteCorrelations(data,columns,percentile,minCorr):\n",
      "    modData = data[columns].T.drop_duplicates().T\n",
      "    path = 'R:\\\\apps\\sophis_value\\GAR_Bulk_VolCorrelUpload\\Simple_INPUT.csv'\n",
      "    Correlations = ComputeCorrelation(modData,modData.columns,percentile,minCorr)\n",
      "    Returns = modData.pct_change()\n",
      "    WriteToCsv(Correlations,path,len(Correlations),Returns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Old Section\n",
      "#MakeNwriteCorrelations(df,usedTickers,80,40)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getData(path,start,end):\n",
      "    head = ['Date','Stock','Price']\n",
      "    data = pd.read_csv(path,sep='\\t+',names=head,parse_dates=['Date']).dropna()\n",
      "    data.Price = [float(x.replace(',','.')) for x in data.Price]\n",
      "    return data.pivot(columns='Stock',values='Price',index='Date')[start:end]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Loading Stocks\n",
      "engine = 'python'\n",
      "path = 'G:\\Strukturering\\Magnus\\Data\\stocks20150401.sqy'\n",
      "start = pd.Timestamp('2008-02-01')\n",
      "end = pd.Timestamp('2015-03-31')\n",
      "df = getData(path,start,end)\n",
      "df = df[['JCP.N','BBY.N','ANF.N','WHR.N','TLSN.ST','ERICb.ST']]\n",
      "Corrs = ComputeCorrelation(df,df.columns,80,20)\n",
      "MakeNwriteCorrelations(df,df.columns,90,25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "written to file: R:\\apps\\sophis_value\\GAR_Bulk_VolCorrelUpload\\Simple_INPUT.csv at : 2015-04-27 15:27:34.854000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py:615: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators; you can avoid this warning by specifying engine='python'.\n",
        "  ParserWarning)\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Loading Indexes\n",
      "path = 'G:\\Strukturering\\Magnus\\Data\\index20150401.sqy'\n",
      "start = pd.Timestamp('2008-02-01')\n",
      "end = pd.Timestamp('2015-03-31')\n",
      "df = getData(path,start,end)\n",
      "\n",
      "MakeNwriteCorrelations(df,df.columns,80,20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "written to file: R:\\apps\\sophis_value\\GAR_Bulk_VolCorrelUpload\\Simple_INPUT.csv at : 2015-04-27 15:27:39.204000\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Loading using the allfile.\n",
      "path = 'G:\\Strukturering\\Magnus\\Data\\Stocks20150410.sqy'\n",
      "start = pd.Timestamp('2008-02-01')\n",
      "end = pd.Timestamp('2015-03-31')\n",
      "df = getData(path,start,end)\n",
      "MakeNwriteCorrelations(df,df.columns,90,25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "written to file: R:\\apps\\sophis_value\\GAR_Bulk_VolCorrelUpload\\Simple_INPUT.csv at : 2015-04-27 15:28:14.919000\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "emptyHead = ['' for x in xrange(10)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Finding minimum Correlation Matrix\n",
      "#Defining start Correlation Matrix\n",
      "CorrL = Corrs\n",
      "iMax = len(StartCorr.columns)\n",
      "#Producing a greedy algo that starts joining the smallest pairs together until we have a 4 cycle. <- not a viable methodology\n",
      "# m\n",
      "#Do a brute force search....\n",
      "Nmn = []\n",
      "Nmn_Best = []\n",
      "NBest = 99999\n",
      "size = 3\n",
      "tmpMtrx = np.zero([size,size])\n",
      "\n",
      "# picks next number compares to the list in compTo (to determine the total distance)\n",
      "def Picknext(CMtrx,compTo):\n",
      "    tmpDist= 0\n",
      "    bstDist = 99999\n",
      "    bstInd = 0\n",
      "    for y in CMtrx: \n",
      "        if not(y in compTo):\n",
      "            tmpDist = np.sum([y-x for x in compTo])\n",
      "            if tmpDist < bstDist:\n",
      "                bstInd = y\n",
      "    return y\n",
      "for i in range(0,iMax):\n",
      "    Nmn.append (CorrL.columns[i])\n",
      "    for j in range(i,iMax):\n",
      "        oldNmn = Nmn.copy()\n",
      "        Nmn.append (Picknext(CorrL,oldNmn))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'StartCorr' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-16-ad000cf5d4d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#Defining start Correlation Matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mCorrL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCorrs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0miMax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStartCorr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#Producing a greedy algo that starts joining the smallest pairs together until we have a 4 cycle. <- not a viable methodology\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'StartCorr' is not defined"
       ]
      }
     ],
     "prompt_number": 16
    }
   ],
   "metadata": {}
  }
 ]
}